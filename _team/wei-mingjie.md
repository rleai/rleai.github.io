---
layout: profile
title: Wei, Mingjie
name: Wei, Mingjie
role: Ph.D. Candidate
image: /assets/img/team/wei-mingjie.jpg
email: mjwei@ir.hit.edu.cn

education:
  - degree: Ph.D. Candidate in Computer Science and Technology
    institution: Harbin Institute of Technology
    period: 2023-Present (2023-2025 as Master)
    advisor: Prof. Zhang Wei-Nan
  - degree: B.Sc. in Software Engineering
    institution: Guangdong University of Foreign Studies (GDUFS)
    period: 2018-2022

research_areas:
  - Embodied Intelligence (EAI)
  - Large Vision Language Model (LVLM)
  - Reinforcement Learning (RL)
  - Vision Language Action Model (VLA)

biography: |
  Wei Mingjie is currently a Ph.D. student jointly trained by Harbin Institute of Technology (HIT) and Zhongguancun Academy (bjzgca), enrolled in the Fall of 2025. I’m supervised by [Prof. Yu Chao](https://scholar.google.com.hk/citations?hl=en&user=BYoq_bwAAAAJ) and [Prof. Zhang Weinan](https://scholar.google.com/citations?user=DBLdEf4AAAAJ&hl=zh-CN). My primary research interests include Embodied Intelligence, Large Vision Large Models, Reinforcement Learning, and Vision-Language-Action model.

I will start my studies at bjzgca in September this year. From the Fall of 2023 to the Summer of 2025, I have served as the team leader (collaborating with [SCIR](https://ir.hit.edu.cn/) Lab at HIT, [State Key Laboratory of Robotics and Systems](https://robot.hit.edu.cn/#) at HIT, and [Shenzhen Leju Robot](https://www.lejurobot.com/zh)) to develop an Intelligent Service Robot for Exhibition/Hall scenario, which are currently operational in several exhibition halls.

I have previously completed a research internship at Li Auto and served as a research assistant (RA) at the Chinese University of Hong Kong, Shenzhen. Regarding academic publications, I have authored two papers published in CCF A-level conferences, with an additional survey paper on Embodied Intelligence currently under journal review.

publications:
  - title: "PRISM: A Benchmark for Unveiling Cross-modal Knowledge Inconsistency in Large Vision-Language Models"
    authors: Mingjie Wei, Wei-Nan Zhang, Chen Zhang, Yifeng Ding, Donglin Di, Lei Ren, Wei Chen, Ting Liu
    venue: ACM Multimedia 2025
    year: 2025
    doi: null
    pdf: null
    abstract: null
    citation: null
  - title: "LLaPa: A Vision-Language Model Framework for Counterfactual-Aware Procedural Planning"
    authors: Shibo Sun, Xue Li, Donglin Di, Mingjie Wei, Lanshun Nie, Wei-Nan Zhang, Dechen Zhan, Yang Song, Lei Fan
    venue: ACM Multimedia 2025
    year: 2025
    doi: null
    pdf: null
    abstract: null
    citation: null

projects:
  - name: "Key Technologies of Exhibition Hall Guide Robots based on Embodied Intelligence"
    description: "We have developed a multi-agent framework, which consists of multiple agents, including a large model for user's intent recognition, a large model for navigation waypoint extraction, a large model for robotic action extraction, and a conversational agent enhanced by retrieval and historical dialogues. The framework aims to collaboratively process user instructions to enable intelligent robot interaction and task execution."
    period: "2023.11-2025.06"
    role: "Team Leader, Main Contributor"
    institution: "Harbin Institute of Technology - China Mobile Communications Group Co., Ltd. Joint Research Institute for 5G Application Innovation"
    status: "Completed"

contact:
  email: winstonwei0512@gmail.com
  github: https://github.com/WinstonWmj
  linkedin: null
  google_scholar: null
---
